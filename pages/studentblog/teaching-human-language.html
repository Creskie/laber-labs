<!DOCTYPE html>
<html lang="en">

<head>
	<meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <title>Laber Labs</title>

    <!-- Favicon -->
    <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
	<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
	<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
	<link rel="manifest" href="/site.webmanifest">

    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css">
    <link rel="stylesheet" type="text/css" href="../../css/main.css"/>
    <!-- FontAwesome -->
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.7.2/css/all.css" integrity="sha384-fnmOCqbTlWIlj8LyTjo7mOUStjsKC4pOpQbqyi7RrhN7udi9RwhKkMHpvLbHG9Sr" crossorigin="anonymous">

    <link href="https://fonts.googleapis.com/css?family=Josefin+Sans:300,300i,400,400i,600,600i,700,700i" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Overpass+Mono:400,700" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Mada&display=swap" rel="stylesheet">

    <!-- Hamburger to X animation -->
    <link href="../../css/hamburgers.css" rel="stylesheet">

    <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
</head>

<body>
	<nav class="navbar navbar-expand-lg fixed-top" role="navigation">
        <a class="navbar-brand" href="../../index.html"><img src="../../images/logotype.png" /></a>
            <button class="navbar-toggler hamburger hamburger--squeeze" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" type="button" aria-expanded="false">
                <span class="hamburger-box">
                    <span class="hamburger-inner"></span>
                </span>
            </button>

	    <!-- Hamburger to X animation -->
	    <script>
	      var $hamburger = $(".hamburger");
	      $hamburger.on("click", function(e) {
	        $hamburger.toggleClass("is-active");
	        // Do something else, like open/close menu
	      });
	    </script>

	    <div class="collapse navbar-collapse" id="navbarSupportedContent">
	      	<ul class="navbar-nav ml-auto tabs">
	      		<li class="nav-item"><a class="nav-link" href="../../images/ericlaber_cv.pdf">CV</a></li>
		        <li class="nav-item"><a class="nav-link" href="../team.html">Team</a></li>
		        <li class="nav-item"><a class="nav-link" href="../publications.html">Publications</a></li>
		        <li class="nav-item"><a class="nav-link" href="../projects.html">Projects</a></li>
		        <li class="nav-item dropdown">
		          	<a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Subsets
		          		<i class="fas fa-angle-down"></i>
		          	</a>
		          	<div class="dropdown-menu" role="menu">
			            <a class="dropdown-item" href="../doranslab.html">Doran's Lab</a>
			            <a class="dropdown-item" href="../donkeydarlings.html">Donkey Darlings</a>
			            <a class="dropdown-item" href="../ataristicians.html">Ataristicians</a>
		          	</div>
		        </li>
		        <li class="nav-item dropdown">
		          	<a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Games
		          		<i class="fas fa-angle-down"></i>
		          	</a>
		          	<div class="dropdown-menu" role="menu">
			            <a class="dropdown-item" href="../laserfoxes.html">Laser Foxes</a>
			            <a class="dropdown-item" href="../spacemice.html">Space Mice</a>
			            <a class="dropdown-item" href="../flyingsquirrel.html">Flying Squirrel</a>
			            <a class="dropdown-item" href="../snackattack.html">Snack Attack</a>
			            <a class="dropdown-item" href="../zombiesontreadmills.html">Zombies on Treadmills</a>
			            <a class="dropdown-item" href="../mountboredoom.html">Mount Boredoom</a>
			            <a class="dropdown-item" href="../pac-boy.html">PAC-BOY</a>
		          	</div>
		        </li>
		        <li class="nav-item dropdown">
		          	<a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Videos
		          		<i class="fas fa-angle-down"></i>
		          	</a>
		          	<div class="dropdown-menu" role="menu">
			            <a class="dropdown-item" href="../animations.html">Animations</a>
			            <a class="dropdown-item" href="../workshops.html">Workshops</a>
		          	</div>
		        </li>
		        <li class="nav-item"><a class="nav-link" href="../studentblog.html">Student Blog</a></li>
		        <li class="nav-item"><a class="nav-link" href="../contact.html">Contact</a></li>
	       	</ul>
	    </div>
	</nav>

	<header class="header-white header-blogpost header-half break-out">
		<div class="header-content header-content-blog">
			<div class="col-8 offset-2 header-content-inner">
				<h3 class="subheader-1">Teaching Human Language to a Computer</h3>
				<p class="blog-info">September 1, 2017</p>
				<div class="center">
					<img class="fade-img team-photo" src="../../images/marshall-wang.jpg" />
				</div>
				<p class="blog-info2"><span class="blog-highlight">Longshaokan (Marshall) Wang, PhD Candidate</span></p>
			</div>
		</div>
	</header>

	<section class="additional-section blog-section">
		<div class="container-fluid col-lg-8 offset-lg-2 col-md-10 offset-md-1 col-sm-12">
			<div class="row">
				<div class="col-12">
					<p class="blog-text">Have you ever learned to write code? If so, you were learning a “computer language.” But, have you ever considered the reverse; teaching a computer to “understand” a human language? With the advancement of machine learning techniques, we can now build models to convert audio signals to texts (Automatic Speech Recognition), detect emotions carried by sentences (Sentiment Analysis), identify intentions from texts (Natural Language Understanding), translate texts from one language to another (Machine Translation), synthesize audio signals from texts (Text-To-Speech) and more! In fact, you probably have already been using these models without knowing because they are the brains of the popular artificial intelligence (AI) assistants such as Amazon’s Alexa, Google Assistant, Apple’s Siri, Microsoft’s Cortana, and most likely Iron Man’s Jarvis. If you have ever wondered how these AI assistants interact with you, then you are in luck! We are going to take a high-level look at how these models are built.</p>

					<p class="blog-text">Many of the language-processing tasks listed above use variations of a machine-learning model called Recurrent Neural Network (RNN). But, let’s start from the very beginning. Say you spotted an animal you haven’t seen before, and you attempt to classify it. Your brain is implicitly considering multiple factors (or features): Is it big? Does it make a noise? Does it have a tail?, etc. You weight these factors differently because maybe the color of its fur is not as important as the shape of its face. Then, your guess will be the “closest” animal you know. A machine-learning model for classification works similarly. It maps a set of input features (e.g., big, purrs, has a tail, …) to a classification label (cat). First, the model needs to be trained using samples with correct labels, so that it knows what features correspond to each label. Then, given the features of a new sample, the model can assign it to the “closest” label it knows.</p>

					<p class="blog-text">A simple example of a classification model is a perceptron. This model uses a weighted sum of the input features to produce a binary classification based on whether the sum passes a threshold:</p>
				</div>

				<div class="col-lg-4 offset-lg-4 col-6 offset-3">
					<img class="blog-image2 fade-img mx-auto d-block" src="../../images/perceptron.png">
					<p class="blog-caption">[1]</p>
				</div>

				<div class="col-12">
					<p class="blog-text">But a perceptron is too simple for many tasks, such as the “Exclusive Or (XOR)” problem. In XOR problems with 2 input variables, the correct classification is 1 if only one input variable is 1, and 0 otherwise:</p>
				</div>

				<div class="col-6 offset-3">
					<table class="blog-table">
						<tr>
							<th>Values of input variables A and B</th>
							<th>True output/correct classification</th>
						</tr>
						<tr>
							<th>A = 0, B = 0</th>
							<th>0</th>
						</tr>
						<tr>
							<th>A = 1, B = 0</th>
							<th>1</th>
						</tr>
						<tr>
							<th>A = 0, B = 1</th>
							<th>1</th>
						</tr>
						<tr>
							<th>A = 1, B = 1</th>
							<th>0</th>
						</tr>
					</table>
				</div>

				<div class="col-12">
					<p class="blog-text">However, this classification rule is impossible for a perceptron to learn. To see this, note that if there are only two input features, a perceptron essentially draws a line in the plane to separate the 2 classes, and in the XOR problem, a line can never classify the labels correctly (separate the yellow and gray dots):</p>
				</div>

				<div class="col-lg-4 offset-lg-4 col-6 offset-3">
					<img class="blog-image2 fade-img mx-auto d-block" src="../../images/perceptron-line.png">
					<p class="blog-caption">[2]</p>
				</div>

				<div class="col-12">
					<p class="blog-text">To handle more complicated tasks, we need to make our model more flexible. One method is to stack multiple perceptrons to form a layer, stack multiple layers to form a network, and add non-linear transformations to the perceptrons:</p>
				</div>

				<div class="col-lg-4 offset-lg-4 col-6 offset-3">
					<img class="blog-image2 fade-img mx-auto d-block" src="../../images/perceptron-layer.png">
					<p class="blog-caption">[3]</p>
				</div>

				<div class="col-12">
					<p class="blog-text">The result is called an Artificial Neural Network (ANN). Instead of learning only a linear separation, this model can learn extremely complicated classification rules. We can increase the number of layers to make the model “deep” and more powerful, which we refer to as a Deep Neural Network (DNN) or Deep Learning.</p>

					<p class="blog-text">Despite the flexibility of the DNN model, language processing remains a challenging classification task, however. For starters, sentences can have different lengths. In cases like Machine Translation, the output is not just a single label. What’s more, how can we train a model to extract useful linguistic features on its own? Just think about how hard it is for a human to become a linguist. So, to handle language processing, we need a few more twists on our DNN model.</p>

					<p class="blog-text">To deal with the variable lengths of sentences, one can employ a method known as word embedding. Here, each word of a sentence is processed individually and mapped to a numeric vector of a fixed length. A good word embedding tends to put words with related meanings, such as “dolphin” and “SeaWorld,” close to one another in the vector space and words with distinct meanings far apart:</p>
				</div>

				<div class="col-lg-4 offset-lg-4 col-6 offset-3">
					<img class="blog-image2 fade-img mx-auto d-block" src="../../images/word-embedding.png">
					<p class="blog-caption">[4]</p>
				</div>

				<div class="col-12">
					<p class="blog-text">The embeddings are then fed to the DNN for classification.</p>

					<p class="blog-text">But a word’s meaning and function also depend on its context in the sentence! How can we preserve the context when processing a sentence word by word? Instead of using only the current word as our DNN’s input, we also use the output of our DNN for the previous word as an additional input. The resulting structure is called a Recurrent Neural Network (RNN) because the previous output becomes part of the current input:</p>
				</div>

				<div class="col-lg-4 offset-lg-4 col-6 offset-3">
					<img class="blog-image2 fade-img mx-auto d-block" src="../../images/rnn-structure.png">
					<p class="blog-caption">[5]</p>
				</div>

				<div class="col-12">
					<p class="blog-text">Now we know how to make our model “read” a sentence, but how do we format all the language-processing tasks as classification problems? It’s straightforward in Sentiment Analysis, where we use the output of an RNN for the last word as a summary for the sentence and add a simple classification model on top of the summary. The labels can be [“positive”, “neutral”, “negative”] or [“happy”, “angry”, “sad,”  …]. In Machine Translation, we have an encoder RNN and a decoder RNN. The encoder reads and summarizes the sentence in language A; the decoder sequentially generates the translation word-by-word in language B. Given what you’ve learned so far, can you figure out how to use a RNN for Natural Language Understanding, Automatic Speech Recognition, and Text-To-Speech?</p>

					<p class="blog-text">On this journey, we started with the basic classification model, the perceptron, and finished with the bleeding-edge classification models that can process human language. We have peeked into the brains of the AI assistants. Exciting research in language processing is happening as we speak, but there is still a long road ahead for the AI assistants to converse like humans. Language processing is, as mentioned before, not easy. At least next time you get frustrated with Siri, instead of yelling “WHY ARE YOU SO DUMB?” you can yell “YOU CLASSIFIED MY INTENTION WRONG! DO YOU NEED A BETTER EMBEDDING?”</p>

					<p class="blog-text italic">References<br>[1] Programming a Perceptron in Python, 2013, Danilo Bargen.<br>[2] A deep learning tutorial: from perceptrons to deep networks, 2014, Ivan Vasilev.<br>[3] Overview of artificial neural networks and its applications, 2017, Jagreet.<br>[4] Wonderful world of word embeddings: what are they and why are they needed?, 2017, Madrugado.<br>[5] Understanding LSTM networks, 2015, Colah.</p>
				</div>
				<!-- Additional questions -->
				<div class="col-12 blog-additional">
					<p class="blog-text3 horizontal-rule">Marshall is a PhD Candidate whose research focuses on artificial intelligence, machine learning, and sufficient dimension reduction. We asked a fellow Laber Labs colleague to ask Marshall a probing question.</p>
					<ul>
						<li>
							<p class="interview-question">If you were running a company in Boston and had summer interns coming from out of town, what would be the best way to scam some money off of them? —James Gilman</p>
							<p class="blog-text2">Call my company Ataristicians and ask for seed money.</p>
							<p class="blog-text2">Just kidding. On a more serious note, if I were a scammer, I would take advantage of the fact that in Boston, gifting weed is legal but selling is not. The way transaction works is that the buyer would “accidentally” drop his money and then pick up the “gift bag” from the seller. The employees of my company would go to all the intern events, establish contacts with the interns, find the potential customers, and pose as discrete weed dealers. Then we would simply put garbage in the gift bag and take the interns “dropped” money. Nothing illegal with gifting garbage. Those interns can’t find help from the police. And because they came from out of town, they are unlikely to have connections with local gangs. Now, if we want to make more money, we would record the whole price negotiations and the transactions, then blackmail the interns, threatening to email the recordings to their managers and ruin their careers.</p>
						</li>
					</ul>
					<p class="blog-text3">This is Marshall’s second post! To learn more about his research, check out his first article <a class="link" href="terminator-to-skynet.html">here</a>!</p>
				</div>
			</div>
			<div class="row">
				<div class="col-12 d-flex flex-row-reverse">
					<div class="button2-container padding-left">
						<a href="grad-school-miserable.html" class="btn2 btn-primary2">Next <i class="fas fa-arrow-right"></i></a>
					</div>
					<div class="button2-container padding-left">
						<a href="variable-selection-lasso.html" class="btn2 btn-primary2"><i class="fas fa-arrow-left"></i> Previous</a>
					</div>
					<div class="button2-container padding-left">
						<a href="../studentblog.html" class="btn2 btn-primary2">View All Posts</a>
					</div>
				</div>
			</div>
		</div>
	</section>

	<section class="footer">
		<div class="container-fluid">
			<div class="row">
				<div class="col-lg-4 col-md-4 col-sm-12 footer-section">
				</div>
				<div class="col-lg-4 col-md-4 col-sm-12 footer-section">
					<span class="fa-stack fa-lg">
  						<a href="https://twitter.com/LaberLabs"><i class="fab fa-twitter"></i></a>
					</span>
					<span class="fa-stack fa-lg">
  						<a href="https://www.facebook.com/LaberLabs/"><i class="fab fa-facebook"></i></a>
					</span>
					<span class="fa-stack fa-lg">
  						<a href="https://www.youtube.com/c/LaberLabs"><i class="fab fa-youtube"></i></a>
					</span>
				</div>
				<div class="col-lg-4 col-md-4 col-sm-12 footer-section">
					<p class="footer-contact">Let's Talk Stats!</p>
					<p class="footer-email"><a href="mailto:laber@stat.ncsu.edu">laber@stat.ncsu.edu</a></p>
				</div>
			</div>
		</div>
	</section>

	<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
	<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>
    <script type="text/javascript" src="../../js/main.js"></script>
</body>
